{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data cornll05\n",
    "# TODO change datareader\n",
    "# train model\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-61-3794fa5ffebd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-3794fa5ffebd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    - [x] pull out the last hidden states and make it a sentence embedding\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "- [x] pull out the last hidden states and make it a sentence embedding\n",
    "- [x] read in image features\n",
    "- [x] choose a score funciton between image feature and sentence embedding\n",
    "- [x] integrate the score function into loss function\\\n",
    "- [x] text to instance funciton need to be defined\n",
    "- [x] give model parameter in config file, leave others to allennlp config\n",
    "- [x] train\n",
    "- [ ] To be decided\n",
    "\n",
    "found for 18177 out of 30190 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- [x] Change datareader to cornll05 train set formmat\n",
    "- [x]  run model for test:\n",
    "- [x] change model to accept json train test data\n",
    "- [x] invalid sentence problem, some sentence does not have verb in it.\n",
    "- [x] test model\n",
    "- [ ] adding image attenter into the model\n",
    "    * image to conv features? easiest way is to use plain attention\n",
    "    * attention layer\n",
    "    * plain encoder: image, decoder, text\n",
    "    \n",
    "- [ ] see performance \n",
    "- [ ] make some results:\n",
    "    - [ ] adding parsing\n",
    "- [ ] transformer\n",
    "- [ ] different alignment\n",
    "- [ ] \n",
    "Intuition\n",
    "\n",
    "By trying to align image with sentence\n",
    "the sentence representation learning part would learn gain more information during optimzing, and \n",
    "the sentence representation acquired will make be grounded to the image\n",
    "Thus, intrinsic knowledge is embeded into the representation, and when testing, even without the image part, model can do inference with \"image knowledge in mind\", and idealy do it better.\n",
    "\n",
    "m to overturn the\n",
    "long-held belief that syntactic parsing is a prerequisite for this task (Punyakanok et al., 2008).\n",
    "\n",
    "g Zhou and Xu (2015), we treat SRL as a\n",
    "BIO tagging problem \n",
    "\n",
    "introducing highway connections (Srivastava et al., 2015; Zhang\n",
    "et al., 2016), (3) using recurrent dropout (Gal\n",
    "and Ghahramani, 2016), (4) decoding with BIOconstraints, and (5) ensembling with a product of\n",
    "experts\n",
    "\n",
    "1) design choices on architecture, initialization, and\n",
    "regularization that have a surprisingly large impact on model performance; (2) different types of\n",
    "prediction errors showing, e.g., that deep models\n",
    "excel at predicting long-distance dependencies but\n",
    "still struggle with known challenges such as **PPattachment errors and adjunct-argument distinctions; **\n",
    "\n",
    "cross entropy with sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the datareader to cornll05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls /media/data/srl/srl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontonotes_datapath = '/media/data/srl/srl/conll-formatted-ontonotes-5.0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from allennlp.data.dataset_readers import SrlReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.token_indexers import SingleIdTokenIndexer, TokenIndexer\n",
    "from allennlp.data.fields import Field, TextField, SequenceLabelField, MetadataField\n",
    "from allennlp.data.instance import Instance\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from allennlp.data.tokenizers import Token\n",
    "import logging\n",
    "from typing import Dict, List, Iterable, Tuple, Any\n",
    "from allennlp.common.file_utils import cached_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers import SrlReader\n",
    "from allennlp.models import srl_bert\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_reader = SrlReader(lazy=True, domain_identifier='train')\n",
    "\n",
    "# train_data = train_reader.read(ontonotes_datapath)\n",
    "\n",
    "# test_reader = SrlReader(lazy=True, domain_identifier='test')\n",
    "# test_data = test_reader.read(ontonotes_datapath)\n",
    "\n",
    "# val_reader = SrlReader(lazy=True, domain_identifier='development')\n",
    "# val_data = val_reader.read(ontonotes_datapath)\n",
    "\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read(file_path):\n",
    "    file_path = cached_path(file_path)\n",
    "    logger.info(f\"Reading SRL instances fro dataset files at:{file_path}\")\n",
    "    with open(file_path) as f:\n",
    "        for line in f.readlines():\n",
    "            srl = json.loads(line)\n",
    "            tokens = [Token(t) for t in srl[\"words\"]]\n",
    "            tags = srl['verbs'][0]['tags']\n",
    "            verb_indictor = [1 if label[-2:] == \"-V\" else 0 for label in tags]\n",
    "            yield self.tokens, verb_indictor, tags\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSrlReader(SrlReader):\n",
    "    def _read(self, file_path):\n",
    "        file_path = cached_path(file_path)\n",
    "        logger.info(f\"Reading SRL instances fro dataset files at:{file_path}\")\n",
    "        with open(file_path) as f:\n",
    "            for line in f.readlines():\n",
    "                srl = json.loads(line)\n",
    "                tokens = [Token(t) for t in srl[\"words\"]]\n",
    "                tags = srl['verbs'][0]['tags']\n",
    "                verb_indictor = [1 if label[-2:] == \"-V\" else 0 for label in tags]\n",
    "                yield self.text_to_instance(tokens, verb_indictor, tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Create dataset.ipynb'   \u001b[0m\u001b[01;34moutput\u001b[0m/                 srl_label_getter.ipynb\r\n",
      " \u001b[01;34mexperiments\u001b[0m/            README.md               train_new.json\r\n",
      " LICENSE                 srl_json_reader.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/zijiao/work/data/mscoco/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_caps.txt  test_caps.txt          test_new.json   train_ims.npy\r\n",
      "dev_ims.npy   test_ground-truth.txt  train_caps.txt  vocab.pkl\r\n"
     ]
    }
   ],
   "source": [
    "ls ~/work/data/mscoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(file_path, data_split):\n",
    "    return np.load(os.path.join(file_path, f'{data_split}_ims.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image = load_img(file_path, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2048)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
